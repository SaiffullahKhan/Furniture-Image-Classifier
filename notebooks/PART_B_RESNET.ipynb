{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6df09c-07f0-411d-a724-a58338102f89",
   "metadata": {},
   "source": [
    "Datasets taken from kaggle links below:\n",
    "\n",
    "https://www.kaggle.com/datasets/udaysankarmukherjee/furniture-image-dataset (For tv and table)\n",
    "\n",
    "https://www.kaggle.com/datasets/arminajdehnia/antic-chairs (for chair)\n",
    "\n",
    "https://www.kaggle.com/datasets/sunnykusawa/sofas (for sofa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69631048-7362-4615-91f9-55b1f5190c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4acaa42-e2ff-49cb-9b85-7c1b1e14b785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8695b17f-4183-497a-8478-f20dd535d382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7123 images belonging to 4 classes.\n",
      "Found 1780 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 1. Load & Augment Dataset\n",
    "# ===========================\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "validation_split = 0.2  # 20% of the data will be used for validation\n",
    "\n",
    "# Data Augmentation for Training Data\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=validation_split  # Spliting the data into training and validation sets\n",
    ")\n",
    "\n",
    "# Preprocessing for Validation Data (No Augmentation)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_split  # Spliting the data into training and validation sets\n",
    ")\n",
    "\n",
    "# Train Data Generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/student/AIML/PROJECT/PART B DATASETS',  # this is my directory thats containing all the images\n",
    "    target_size=(img_height, img_width),  \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Specify that this is the training set\n",
    ")\n",
    "\n",
    "# Validation Data Generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'C:/student/AIML/PROJECT/PART B DATASETS',  # Same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5550708b-b945-4a7c-8a06-78db9a393493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: {0: 'Chair_Images', 1: 'Sofa_Images', 2: 'TV_Images', 3: 'Table_Images'}\n"
     ]
    }
   ],
   "source": [
    "# Class labels\n",
    "labels = train_generator.class_indices\n",
    "labels = dict((v, k) for k, v in labels.items())\n",
    "print(\"Class labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0c7add-6927-4521-9873-fb35252dafb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 2. Build CNN Model (RESNET50)\n",
    "# ===========================\n",
    "\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(img_height, img_width, 3))\n",
    "base_model.trainable = False  # for freezing pretrained layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2728ca-462d-4a04-9cf7-b90245adb35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating new model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401b2e5d-6692-4247-857f-6308f0ea1715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 6, 6, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               9437312   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 33,025,540\n",
      "Trainable params: 9,437,828\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf2fdb2-4251-49cf-a792-aa246940e8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 3. Compile & Train Model\n",
    "# ===========================\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa639271-528b-44cc-896c-89accb666368",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "223/223 [==============================] - 158s 709ms/step - loss: 1.3731 - accuracy: 0.5856 - val_loss: 0.4778 - val_accuracy: 0.8225\n",
      "Epoch 2/10\n",
      "223/223 [==============================] - 157s 706ms/step - loss: 0.6196 - accuracy: 0.7182 - val_loss: 0.4745 - val_accuracy: 0.8219\n",
      "Epoch 3/10\n",
      "223/223 [==============================] - 157s 704ms/step - loss: 0.5668 - accuracy: 0.7429 - val_loss: 0.3254 - val_accuracy: 0.8871\n",
      "Epoch 4/10\n",
      "223/223 [==============================] - 157s 703ms/step - loss: 0.4981 - accuracy: 0.7644 - val_loss: 0.2317 - val_accuracy: 0.9404\n",
      "Epoch 5/10\n",
      "223/223 [==============================] - 158s 710ms/step - loss: 0.4606 - accuracy: 0.7814 - val_loss: 0.1935 - val_accuracy: 0.9511\n",
      "Epoch 6/10\n",
      "223/223 [==============================] - 158s 707ms/step - loss: 0.4188 - accuracy: 0.7984 - val_loss: 0.1619 - val_accuracy: 0.9551\n",
      "Epoch 7/10\n",
      "223/223 [==============================] - 158s 707ms/step - loss: 0.4287 - accuracy: 0.7915 - val_loss: 0.1396 - val_accuracy: 0.9646\n",
      "Epoch 8/10\n",
      "223/223 [==============================] - 158s 707ms/step - loss: 0.4445 - accuracy: 0.7879 - val_loss: 0.1549 - val_accuracy: 0.9674\n",
      "Epoch 9/10\n",
      "223/223 [==============================] - 160s 717ms/step - loss: 0.4163 - accuracy: 0.8071 - val_loss: 0.1708 - val_accuracy: 0.9843\n",
      "Epoch 10/10\n",
      "223/223 [==============================] - 158s 709ms/step - loss: 0.5416 - accuracy: 0.7549 - val_loss: 0.2963 - val_accuracy: 0.9545\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d22b0b-561c-4010-93ad-4d75129901e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model as furniture_model_RESNET.h5\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 4. Save Trained Model\n",
    "# ===========================\n",
    "\n",
    "model.save(\"furniture_model_RESNET.h5\")\n",
    "print(\"Saved model as furniture_model_RESNET.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d4d622-1b7c-4251-8d1d-85fdc9c55209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 30s 540ms/step - loss: 0.2963 - accuracy: 0.9545\n",
      "Validation Accuracy: 95.45%\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 5. Evaluate Model\n",
    "# ===========================\n",
    "\n",
    "scores = model.evaluate(validation_generator, verbose=1)\n",
    "print(f\"Validation Accuracy: {scores[1] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f4c82-f22d-4bb4-99ee-36d4fd2187e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
